# SGLD on a simple non-convex function

import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import minimize

# Constants
epsilon = 0.1

# Set up experiments for several dimensions.
# SGLD parameters
eta = 1e-3        # step size
n_steps = 20000   # number of iterations
beta=0.5
sigma = np.sqrt(2*eta/beta)  # noise scale (assuming unit temperature)
dimensions = [2, 10, 50, 100]
results = {}

def f(x):
    # Extract the first coordinate
    x1 = x[0]
    # Compute the "tilted" double-well part in x1.
    well_part = x1**4 - 5*x1**2 + 0.9*x1
    # Add the quadratic penalty for the rest of the coordinates.
    quadratic_part = np.sum(x[1:]**2)
    return well_part + quadratic_part

def grad_f(x):
    grad = np.zeros_like(x)
    # Gradient with respect to x1.
    grad[0] = 4*x[0]**3 - 10*x[0] + 0.9
    # For x2, ..., xn, the derivative is simply 2*x_i.
    grad[1:] = 2*x[1:]
    return grad

def get_global_minimizer(d):
    global_minimizer = np.zeros(d)
    global_minimizer[0] = -1.624
    return global_minimizer

def run_sgld(d, x0):
    """
    Run SGLD for a d-dimensional function.
    Returns the distance from the minimizer at each iteration.
    """
    x = np.copy(x0)
    x_min = get_global_minimizer(d)
    distances = []
    # eta = 0.01
    for i in range(n_steps):
        grad = grad_f(x)
        # SGLD update
        noise = np.random.randn(d)
        x = x - eta * grad + sigma * noise * np.sqrt(1)
        # eta = eta / (np.sqrt(i+1))
        distances.append(f(x)-f(x_min))
        # distances.append()
    print(x[0])
    print(np.linalg.norm(x-x_min))
    return np.array(distances)

# We want the same initial Euclidean distance from the minimizer for each d.
# Let delta be that distance.
delta = 5.0   # total Euclidean distance from the minimizer.

for d in dimensions:
    x_min = get_global_minimizer(d)
    v=np.ones(d)
    x0 = delta*(v / np.linalg.norm(v))  # ensures ||x0 - x_min|| = delta
    print(f"Running SGLD for d = {d} with initial Euclidean distance = {np.linalg.norm(x0 - x_min):.2f}")
    results[d] = run_sgld(d, x0)

# Plotting the distance from the minimizer against iterations for each dimension.
plt.figure(figsize=(10, 10))
for d in dimensions:
    plt.plot(results[d], label=f'd = {d}')
    # plt.hist(results[d], bins=30, alpha=0.5, label=f"d = {d}", density=True)

plt.xlabel('iterations')
plt.ylabel('f(x) - f(x*)')
plt.title('SGLD: Distance from the global minimizer across iterations')
plt.legend()
plt.grid(True)
plt.show()
